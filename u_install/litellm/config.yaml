# A config file to use ollama models
#  as if they are OpenAI models
# Refer: https://docs.litellm.ai/docs/providers/ollama
model_list:
  - model_name: "mistral:latest"             
    litellm_params:
      model: "ollama_chat/mistral:latest"
      api_base: "http://localhost:11434"
