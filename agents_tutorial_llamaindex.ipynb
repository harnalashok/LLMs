{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harnalashok/LLMs/blob/main/agents_tutorial_llamaindex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Last amended: 2nd April, 2024\n",
        "# Refer YouTube Video\n",
        "#  https://www.youtube.com/watch?v=bHn4dLJYIqE"
      ],
      "metadata": {
        "id": "QbG6lI3OQWww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Roadmap\n",
        "\n",
        "Part-4 This video focus:\n",
        "\n",
        "- Function Calling Agents + Agent Runner\n",
        "- Agentic RAG\n",
        "- Project - ReACT Agent: Building a Search Assistant Agent\n"
      ],
      "metadata": {
        "id": "TTfHYu4vTTy7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Software Install"
      ],
      "metadata": {
        "id": "dZM05XOTRYil"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index-embeddings-huggingface\n",
        "!pip install llama-index-embeddings-instructor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MAW5MXnwpct",
        "outputId": "3c72103b-b20c-473d-f231-f544a2548593"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index-embeddings-huggingface\n",
            "  Downloading llama_index_embeddings_huggingface-0.5.2-py3-none-any.whl.metadata (767 bytes)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.29.3)\n",
            "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-embeddings-huggingface) (0.12.28)\n",
            "Requirement already satisfied: sentence-transformers>=2.6.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-embeddings-huggingface) (3.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.13.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.11.14)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2.0.40)\n",
            "Requirement already satisfied: banks<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2.1.1)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.2.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.4.2)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2.11.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (9.0.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.9.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.17.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (4.50.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.14.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.18.3)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.11/dist-packages (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.7.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.1.6)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (4.3.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2024.11.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2.33.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.1.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.5.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.26.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.14.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.6.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.3.1)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.11/dist-packages (from griffe->banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.0.2)\n",
            "Downloading llama_index_embeddings_huggingface-0.5.2-py3-none-any.whl (8.9 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, llama-index-embeddings-huggingface\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed llama-index-embeddings-huggingface-0.5.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Collecting llama-index-embeddings-instructor\n",
            "  Downloading llama_index_embeddings_instructor-0.3.0-py3-none-any.whl.metadata (808 bytes)\n",
            "Collecting instructorembedding<2.0.0,>=1.0.1 (from llama-index-embeddings-instructor)\n",
            "  Downloading InstructorEmbedding-1.0.1-py2.py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-embeddings-instructor) (0.12.28)\n",
            "Collecting sentence-transformers<3.0.0,>=2.2.2 (from llama-index-embeddings-instructor)\n",
            "  Downloading sentence_transformers-2.7.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: torch<3.0.0,>=2.1.2 in /usr/local/lib/python3.11/dist-packages (from llama-index-embeddings-instructor) (2.6.0+cu124)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (2.0.40)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (3.11.14)\n",
            "Requirement already satisfied: banks<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (2.1.1)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (2025.3.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (3.4.2)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (2.11.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (9.0.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (4.13.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (1.17.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers<3.0.0,>=2.2.2->llama-index-embeddings-instructor) (4.50.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers<3.0.0,>=2.2.2->llama-index-embeddings-instructor) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers<3.0.0,>=2.2.2->llama-index-embeddings-instructor) (1.14.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers<3.0.0,>=2.2.2->llama-index-embeddings-instructor) (0.29.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-instructor) (3.18.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-instructor) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-instructor) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-instructor) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-instructor) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-instructor) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-instructor) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-instructor) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-instructor) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-instructor) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-instructor) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-instructor) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-instructor) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-instructor) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-instructor) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-instructor) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-instructor) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0.0,>=2.1.2->llama-index-embeddings-instructor) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (1.18.3)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.11/dist-packages (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (1.7.2)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (4.3.7)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers<3.0.0,>=2.2.2->llama-index-embeddings-instructor) (24.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (2024.11.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (2.33.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (3.1.1)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers<3.0.0,>=2.2.2->llama-index-embeddings-instructor) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers<3.0.0,>=2.2.2->llama-index-embeddings-instructor) (0.5.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (3.26.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0.0,>=2.1.2->llama-index-embeddings-instructor) (3.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers<3.0.0,>=2.2.2->llama-index-embeddings-instructor) (3.6.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (1.3.1)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.11/dist-packages (from griffe->banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-instructor) (0.4.6)\n",
            "Downloading llama_index_embeddings_instructor-0.3.0-py3-none-any.whl (3.6 kB)\n",
            "Downloading InstructorEmbedding-1.0.1-py2.py3-none-any.whl (19 kB)\n",
            "Downloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: instructorembedding, sentence-transformers, llama-index-embeddings-instructor\n",
            "  Attempting uninstall: sentence-transformers\n",
            "    Found existing installation: sentence-transformers 3.4.1\n",
            "    Uninstalling sentence-transformers-3.4.1:\n",
            "      Successfully uninstalled sentence-transformers-3.4.1\n",
            "Successfully installed instructorembedding-1.0.1 llama-index-embeddings-instructor-0.3.0 sentence-transformers-2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.0\n",
        "# For llamaIndex\n",
        "!pip install llama-index  -q\n",
        "\n",
        "# For web search using No API\n",
        "!pip install duckduckgo-search  -q\n",
        "\n",
        "# For using groq\n",
        "!pip install llama-index-llms-groq  -q\n",
        "\n",
        "# For using mistalai\n",
        "!pip install llama-index-llms-mistralai -q\n",
        "\n",
        "# For using mistralai embeddings\n",
        "!pip install llama-index-embeddings-mistralai -q\n",
        "\n",
        "!pip install llama-index-embeddings-huggingface -q\n",
        "!pip install llama-index-embeddings-instructor -q\n",
        "\n",
        "# For ollama"
      ],
      "metadata": {
        "id": "I3j-PwdbVX15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a240cc5-c612-4f79-d3f4-1bee86552b33"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.9/253.9 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.3/302.3 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.2/129.2 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.6/77.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\n",
            "Usage:   \n",
            "  pip3 install [options] <requirement specifier> [package-index-options] ...\n",
            "  pip3 install [options] -r <requirements file> [package-index-options] ...\n",
            "  pip3 install [options] [-e] <vcs project url> ...\n",
            "  pip3 install [options] [-e] <local project path> ...\n",
            "  pip3 install [options] <archive url/path> ...\n",
            "\n",
            "no such option: -a\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.7/288.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function Calling\n",
        "predict and call"
      ],
      "metadata": {
        "id": "uti017YObghL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For asyncio\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "Yaf8SgrmRnyG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calling libraries:\n",
        "\n",
        "from llama_index.core.tools import FunctionTool\n",
        "from duckduckgo_search import DDGS\n",
        "# The Settings is a bundle of commonly used resources\n",
        "#  used during the indexing and querying stage in a\n",
        "#   LlamaIndex workflow/application.\n",
        "from llama_index.core import Settings\n",
        "from llama_index.llms.mistralai import MistralAI\n",
        "from llama_index.llms.groq import Groq\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.embeddings.mistralai import MistralAIEmbedding # Agentic RAG (Function calling - not required)\n",
        "\n"
      ],
      "metadata": {
        "id": "gPAoYXDEcXin"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define web-search function\n",
        "Using DuckDuckGo -- No API required.    \n",
        "But not good for Job Search. Good for Wikipedia search or for general information"
      ],
      "metadata": {
        "id": "gQskOLhGLqA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a web-search\n",
        "def search(query:str) -> str:\n",
        "  \"\"\"\n",
        "  Args:\n",
        "      query: user prompt\n",
        "  return:\n",
        "  context (str): search results to the user query\n",
        "  \"\"\"\n",
        "  # def search(query:str)\n",
        "  req = DDGS()\n",
        "  response = req.text(query,max_results=4)\n",
        "  context = \"\"\n",
        "  for result in response:\n",
        "    context += result['body']\n",
        "  return context"
      ],
      "metadata": {
        "id": "0NsySK9gcnwJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function search tool\n",
        "search_tool = FunctionTool.from_defaults(fn=search)"
      ],
      "metadata": {
        "id": "6fSTJNfTckW-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Who was the Man of the series in India vs Bangalesh 2024 Test Match?\""
      ],
      "metadata": {
        "id": "pRR0Npf2kFlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "mygroqkey = userdata.get('groqkey')"
      ],
      "metadata": {
        "id": "sl2j3pNwd6oh"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Our LLM\n",
        "#llm = MistralAI(model=\"mistral-large-latest\",api_key=mistral_api)\n",
        "llm = Groq(model=\"llama3-70b-8192\", api_key= mygroqkey)"
      ],
      "metadata": {
        "id": "Qm2YCF9IsvuU"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Just testing if LLM responds:\n",
        "\n",
        "print(llm.complete(\"tell me about AI?\").text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKmG9NAjfFKg",
        "outputId": "bc499724-1ed5-47b3-d5cf-f87647b7ccd5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Artificial Intelligence (AI)! It's a fascinating topic that has been rapidly evolving over the past few decades. AI refers to the development of computer systems that can perform tasks that typically require human intelligence, such as:\n",
            "\n",
            "1. **Learning**: AI systems can learn from data, identify patterns, and make decisions or predictions based on that data.\n",
            "2. **Reasoning**: AI systems can draw conclusions, make inferences, and solve problems using logic and rules.\n",
            "3. **Perception**: AI systems can interpret and understand data from sensors, such as images, speech, and text.\n",
            "\n",
            "The goals of AI research include:\n",
            "\n",
            "1. **Narrow or Weak AI**: Create systems that excel in a specific domain or task, such as playing chess, recognizing faces, or translating languages.\n",
            "2. **General or Strong AI**: Develop systems that possess human-like intelligence, capable of reasoning, learning, and applying knowledge across a wide range of tasks.\n",
            "3. **Superintelligence**: Create systems that significantly surpass human intelligence, potentially leading to exponential growth in technological advancements.\n",
            "\n",
            "Types of AI:\n",
            "\n",
            "1. **Machine Learning (ML)**: A subset of AI that involves training algorithms to learn from data and make predictions or decisions.\n",
            "2. **Deep Learning (DL)**: A type of ML that uses neural networks to analyze data, inspired by the structure and function of the human brain.\n",
            "3. **Natural Language Processing (NLP)**: AI that focuses on understanding, generating, and processing human language.\n",
            "4. **Robotics**: AI that integrates with physical devices, such as robots, to perform tasks that require manipulation and interaction with the environment.\n",
            "\n",
            "Applications of AI:\n",
            "\n",
            "1. **Virtual Assistants**: AI-powered assistants, like Siri, Alexa, and Google Assistant, that can understand voice commands and perform tasks.\n",
            "2. **Image and Speech Recognition**: AI-powered systems that can recognize objects, people, and speech patterns.\n",
            "3. **Healthcare**: AI is used in medical diagnosis, personalized medicine, and drug discovery.\n",
            "4. **Finance**: AI is used in trading, risk management, and fraud detection.\n",
            "5. **Transportation**: AI is used in autonomous vehicles, traffic management, and route optimization.\n",
            "\n",
            "Challenges and Concerns:\n",
            "\n",
            "1. **Job Displacement**: AI may automate certain jobs, leading to unemployment.\n",
            "2. **Bias and Fairness**: AI systems can perpetuate biases present in the data used to train them.\n",
            "3. **Privacy and Security**: AI systems can be vulnerable to cyber attacks and data breaches.\n",
            "4. **Explainability and Transparency**: AI systems can be difficult to understand and interpret, making it challenging to identify errors or biases.\n",
            "\n",
            "To address these challenges, researchers, developers, and policymakers are working together to ensure that AI is developed and used responsibly, with a focus on ethics, transparency, and accountability.\n",
            "\n",
            "This is just a brief overview of AI, but I hope it gives you a good starting point for exploring this fascinating field!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Our embedding model\n",
        "embed_model = HuggingFaceEmbedding(\n",
        "                                   model_name=\"BAAI/bge-small-en-v1.5\"\n",
        "                                  )\n",
        "\n",
        "Settings.embed_model = embed_model"
      ],
      "metadata": {
        "id": "WMAFLQEqeBwP"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Settings.llm = llm\n",
        "Settings.embed_model = embed_model"
      ],
      "metadata": {
        "id": "_2CcgMuldwWs"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "function_call = llm.predict_and_call(\n",
        "                                      [search_tool],             # List of FunctionTools\n",
        "                                      user_msg = query,\n",
        "                                      allow_parallel_tool_calls=True,\n",
        "                                    )"
      ],
      "metadata": {
        "id": "vx9Co0tvj3gE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(function_call)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qebPaE__gZHT",
        "outputId": "0598290f-5c83-4099-ea81-39dd2a44c920"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "llama_index.core.chat_engine.types.AgentChatResponse"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "function_call.response"
      ],
      "metadata": {
        "id": "R-U_rMxagU8W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "8ab3c5e5-7c12-4090-a787-03fe85f661e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"IND vs BDESH 2024/25, India vs Bangladesh Match Report: Jaiswal scored twin fifties as India registered a remarkable win despite two days of no play due to rain in Kanpur Matches ( 6 ) Women's T20 ...India won the two-match IND vs BAN test series by 2-0, with R Ashwin bagging the Man of the Series award. The Indian cricket team extended their home dominance by whitewashing Bangladesh in the two-match IND vs BAN test series. India won by the first test in Chennai by 280 runs and the second test in Kanpur by seven wickets.India defeated Bangladesh by seven wickets in the second Test at Kanpur, sealing the series 2-0. Yashasvi Jaiswal's 51 guided India to a successful chase of 95 runs. Follow Us Trending Photos IND vs BAN: Indian opener Yashavi Jaiswal's exceptional fifty in the second innings guided the hosts to a ...IND vs BDESH 2024/25, India vs Bangladesh Match Report: Bangladesh captain Najmul Hossain Shanto's 82 kept the bowling at bay, but Ashwin and Ravindra Jadeja shared nine wickets\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Second Approach for Function Calling Agent\n",
        "\n",
        "- Function Calling Agent Worker"
      ],
      "metadata": {
        "id": "ALu3OewLeMhm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.agent import FunctionCallingAgent, FunctionCallingAgentWorker"
      ],
      "metadata": {
        "id": "H09n13C0hTtV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = FunctionCallingAgent.from_tools(\n",
        "    [search_tool],\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    allow_parallel_tool_calls=True,\n",
        ")"
      ],
      "metadata": {
        "id": "kkfF1yhtlQjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent.chat(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxvzaWdKlmHx",
        "outputId": "dea04cfb-5eec-4006-9159-ac8526cf42f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Running step 0aae73a7-08d2-477a-9703-bb0d517d075a. Step input: Who was the Man of the series in India vs Bangalesh 2024 Test Match?\n",
            "Added user message to memory: Who was the Man of the series in India vs Bangalesh 2024 Test Match?\n",
            "=== Calling Function ===\n",
            "Calling function: search with args: {\"query\": \"Who was the Man of the series in India vs Bangalesh 2024 Test Match?\"}\n",
            "=== Function Output ===\n",
            "IND vs BDESH 2024/25, India vs Bangladesh Match Report: Jaiswal scored twin fifties as India registered a remarkable win despite two days of no play due to rain in Kanpur Matches ( 6 ) Women's T20 ...IND vs BAN 2024, 2ND Test: Match Presentation Share video on : 1st Oct, 2024 14:17 mins 115.2 k IND vs BAN 2024, 2ND Test: India 2nd Innings Fall of Wickets ... Dressing Room BTS | Impact Fielder of the Series | India vs Bangladesh Test Series 2024 Share video on : 1st Oct, 2024 02:35 mins 98.4 k Rohit Sharma said we are going to go hammer and ...India vs Bangladesh, 2nd Test Day 5 ... Bangladesh in India, 2 Test Series, 2024, Sep 27, 2024 ... to smash five world records on Day 4 of the second Test match against Bangladesh. India team ...IND vs BDESH 2024/25, India vs Bangladesh Match Report: Bangladesh captain Najmul Hossain Shanto's 82 kept the bowling at bay, but Ashwin and Ravindra Jadeja shared nine wickets\n",
            "> Running step cf67fcc3-b21d-48c3-807f-f9bb7a0f9b8d. Step input: None\n",
            "=== LLM Response ===\n",
            "The Man of the Series in the India vs Bangladesh 2024 Test Match was not explicitly mentioned in the search results. However, notable performances included Jaiswal scoring twin fifties and Ashwin and Ravindra Jadeja sharing nine wickets. For the most accurate and up-to-date information, please refer to official cricket sources.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEKm4pH-lou6",
        "outputId": "dcaf3a7d-ca93-4d15-fd7d-09f397d356b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Man of the Series in the India vs Bangladesh 2024 Test Match was not explicitly mentioned in the search results. However, notable performances included Jaiswal scoring twin fifties and Ashwin and Ravindra Jadeja sharing nine wickets. For the most accurate and up-to-date information, please refer to official cricket sources.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Approach -3 and the recommended one: Agent Runner"
      ],
      "metadata": {
        "id": "DuMbO4iXfY2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.agent import AgentRunner"
      ],
      "metadata": {
        "id": "S1K4SBTMSO0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
        "    [search_tool],\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    allow_parallel_tool_calls=True,\n",
        ")\n",
        "agent_runner = AgentRunner(agent_worker)"
      ],
      "metadata": {
        "id": "LBtrtTXdSP9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "runner_response = agent_runner.query(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQMKojtSSXlg",
        "outputId": "7121c6ae-d554-43f3-90e5-d23fbbbd39db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added user message to memory: Who was the Man of the series in India vs Bangalesh 2024 Test Match?\n",
            "=== Calling Function ===\n",
            "Calling function: search with args: {\"query\": \"Who was the Man of the series in India vs Bangalesh 2024 Test Match?\"}\n",
            "=== Function Output ===\n",
            "India vs Bangladesh 2024 T20I Squads. India T20I Squad vs Bangladesh: Suryakumar Yadav (captain), Abhishek Sharma, Sanju Samson (wicketkeeper), Rinku Singh, Hardik Pandya, Riyan Parag, Nitish Kumar Reddy, Shivam Dube, Washington Sundar, Ravi Bishnoi, Varun Chakaravarthy, Jitesh Sharma (wicketkeeper), Arshdeep Singh, Harshit Rana, Mayank Yadav. ...India won the two-match IND vs BAN test series by 2-0, with R Ashwin bagging the Man of the Series award. The Indian cricket team extended their home dominance by whitewashing Bangladesh in the two-match IND vs BAN test series.. India won by the first test in Chennai by 280 runs and the second test in Kanpur by seven wickets.IND vs BDESH 2024/25, India vs Bangladesh Match Report: Jaiswal scored twin fifties as India registered a remarkable win despite two days of no play due to rain in Kanpur Matches ( 6 ) Women's T20 ...Indian players celebrate with the trophy after winning the two match test series against Bangladesh in Kanpur, India, Tuesday, October 1, 2024. ... Sharma celebrates the wicket of Bangladesh's Mehidy Hasan Miraz on the fifth and final day of the second cricket test match between Bangladesh and India in Kanpur, India, Tuesday, October 1, 2024 ...\n",
            "=== LLM Response ===\n",
            "R Ashwin was the Man of the Series in the India vs Bangladesh 2024 Test Match. India won the two-match series by 2-0, with R Ashwin bagging the Man of the Series award. The Indian cricket team extended their home dominance by whitewashing Bangladesh in the two-match series. India won the first test in Chennai by 280 runs and the second test in Kanpur by seven wickets.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "runner_response.response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "Qzs9VUAwlHo8",
        "outputId": "3ba88069-8b91-41f9-94e1-ac0b8f2e627b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'R Ashwin was the Man of the Series in the India vs Bangladesh 2024 Test Match. India won the two-match series by 2-0, with R Ashwin bagging the Man of the Series award. The Indian cricket team extended their home dominance by whitewashing Bangladesh in the two-match series. India won the first test in Chennai by 280 runs and the second test in Kanpur by seven wickets.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "runner_chat = agent_runner.chat(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQbbv2AalGHH",
        "outputId": "2bd06aef-077c-49ea-944a-cccd99372c77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added user message to memory: Who was the Man of the series in India vs Bangalesh 2024 Test Match?\n",
            "=== Calling Function ===\n",
            "Calling function: search with args: {\"query\": \"Who was the Man of the series in India vs Bangalesh 2024 Test Match?\"}\n",
            "=== Function Output ===\n",
            "IND vs BDESH 2024/25, India vs Bangladesh Match Report: Jaiswal scored twin fifties as India registered a remarkable win despite two days of no play due to rain in Kanpur Matches ( 6 ) Women's T20 ...Indian players celebrate with the trophy after winning the two match test series against Bangladesh in Kanpur, India, Tuesday, October 1, 2024. ... Sharma celebrates the wicket of Bangladesh's Mehidy Hasan Miraz on the fifth and final day of the second cricket test match between Bangladesh and India in Kanpur, India, Tuesday, October 1, 2024 ...IND vs BAN 2024, 2ND Test: Match Presentation Share video on : 1st Oct, 2024 14:17 mins 115.2 k IND vs BAN 2024, 2ND Test: India 2nd Innings Fall of Wickets ... Dressing Room BTS | Impact Fielder of the Series | India vs Bangladesh Test Series 2024 Share video on : 1st Oct, 2024 02:35 mins 98.4 k Rohit Sharma said we are going to go hammer and ...Dressing Room BTS | Impact Fielder of the Series | India vs Bangladesh Test Series 2024. Share video on : 01 Oct, 2024 02:35 mins 15 k. Related Videos. Reflection on Series Win with Captain Rohit Sharma, Mohd. ... IND vs BAN 2024, 2ND Test: Match Presentation Share video on : 1st Oct, 2024 14 ...\n",
            "=== LLM Response ===\n",
            "The Man of the series in India vs Bangladesh 2024 Test Match was Rohit Sharma.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "runner_chat.response"
      ],
      "metadata": {
        "id": "ckzZxBNhSvFI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "68704263-a0f2-48ff-c173-ed9057a83b05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The Man of the series in India vs Bangladesh 2024 Test Match was Rohit Sharma.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agentic RAG"
      ],
      "metadata": {
        "id": "4NJpK22rlwHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SimpleDirectoryReader # load your documents"
      ],
      "metadata": {
        "id": "o-MM67xplxb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = SimpleDirectoryReader(input_files=[\"/content/2409.16160v1.pdf\"]).load_data()"
      ],
      "metadata": {
        "id": "Gef_J1n7mS5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "\n",
        "splitter = SentenceSplitter(chunk_size=1024)\n",
        "nodes = splitter.get_nodes_from_documents(documents)"
      ],
      "metadata": {
        "id": "8FFJW-kCWMKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SummaryIndex, VectorStoreIndex\n",
        "\n",
        "summary_index = SummaryIndex(nodes)\n",
        "vector_index = VectorStoreIndex(nodes)"
      ],
      "metadata": {
        "id": "MnGQwNAzdpA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary_query_engine = summary_index.as_query_engine(\n",
        "    response_mode=\"tree_summarize\",\n",
        "    use_async=True,\n",
        ")\n",
        "vector_query_engine = vector_index.as_query_engine()"
      ],
      "metadata": {
        "id": "Yoon5GB-emo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.tools import QueryEngineTool\n",
        "from llama_index.core.query_engine.router_query_engine import RouterQueryEngine\n",
        "from llama_index.core.selectors import LLMSingleSelector"
      ],
      "metadata": {
        "id": "iEqSeA44gqI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary_tool = QueryEngineTool.from_defaults(\n",
        "    query_engine=summary_query_engine,\n",
        "    description=(\n",
        "        \"This Agent is useful to summarize the Research paper in a simplied way by giving intuitions\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "vector_tool = QueryEngineTool.from_defaults(\n",
        "    query_engine=vector_query_engine,\n",
        "    description=(\n",
        "        \"This Agent is useful to answer to the user queries within the paper and retrieve the relevant piece of information\"\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "-eperylZeq6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = RouterQueryEngine(\n",
        "    selector=LLMSingleSelector.from_defaults(),\n",
        "    query_engine_tools=[\n",
        "        summary_tool,\n",
        "        vector_tool,\n",
        "    ],\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "uYVvCR5vghSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"give me technical architecture details in the paper\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRL9ne-pgsux",
        "outputId": "49bb599e-fd70-4ee2-a680-4e3988e900cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;3;38;5;200mSelecting query engine 1: This Agent is useful to answer to the user queries within the paper and retrieve the relevant piece of information.\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNm96Nx8g0Yk",
        "outputId": "3563bda7-9b68-4081-e508-0ef06b49d218"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The provided context does not include explicit details about the technical architecture of the paper. It primarily discusses the capabilities and testing scenarios of a method related to character animation and control. For technical architecture details, you would need to refer to other sections of the paper that specifically describe the model, algorithms, or system design.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#response.source_nodes"
      ],
      "metadata": {
        "id": "CWXXJUiFhMXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response2 = query_engine.query(\"summarize the methodology from the paper\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBMe22JZg7P9",
        "outputId": "101e547a-97c4-494c-f126-320d39cf61b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;3;38;5;200mSelecting query engine 0: This choice is most relevant because it mentions summarizing the research paper in a simplified way by giving intuitions, which aligns with the need to summarize the methodology from the paper..\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIbNspBIhAdr",
        "outputId": "5d72d684-b801-44ad-9ef9-fba942baf2d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The methodology presented in the paper involves a novel framework called MIMO for controllable character video synthesis. The framework decomposes a 2D video into three spatial components: the main human, the underlying scene, and floating occlusions, using hierarchical layers based on 3D depth. These components are then encoded into canonical identity code, structured motion code, and full scene code, which serve as control signals for the synthesis process. The structured motion code is derived from a deformable human body model (SMPL) and camera parameters, enabling more dense pose representation with 3D occlusions. The canonical identity code is obtained by transforming the posed human image to a canonical result in standard A-pose using a pretrained human repose model. The scene and occlusion components are embedded with a shared VAE encoder and re-organized as a full scene code. These latent codes are inserted into a diffusion-based decoder as conditions for video reconstruction. The network is trained using a diffusion noise-prediction loss, with the denoising U-Net and reference-net initialized with pretrained weights from Stable Diffusion (SD) 1.5, and the motion module initialized with weights from AnimateDiff. The training is conducted on 8 NVIDIA A100 GPUs for around 50k iterations with 24 video frames and a batch size of 4.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ReACT Agent\n",
        "\n",
        "Build a simple project: Search Assistant Agent"
      ],
      "metadata": {
        "id": "Mle7H1N9hbrX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.agent import ReActAgent"
      ],
      "metadata": {
        "id": "1c9dx7cghFV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = ReActAgent.from_tools([search_tool], llm=llm, verbose=True,allow_parallel_tool_calls=True)"
      ],
      "metadata": {
        "id": "kf8XVTwAhgNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent.chat(\"tell me about AI with Tarun. Also do analysis and say should people follow him?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDFuZJWehp8z",
        "outputId": "d9cca53e-16f9-4fb4-cb75-091a70d4f5f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Running step 4e7cee18-bfa1-4d4e-ab07-d3e7406eb35b. Step input: tell me about AI with Tarun. Also do analysis and say should people follow him?\n",
            "\u001b[1;3;38;5;200mThought: The current language of the user is English. I need to use a tool to help me answer the question.\n",
            "Action: search\n",
            "Action Input: {'query': 'AI with Tarun'}\n",
            "\u001b[0m\u001b[1;3;34mObservation: 🚀 \"Learn AI for FREE with Tarun!\" 🚀Hold on tight, techies! You're about to launch into the world of AI with Tarun Jain - no money, just fun! 💸🧠By day, he...Tarun is instrumental in creating and developing IBM's next-generation AI platform, watsonx, a revolutionary leap forward in the world of AI for businesses. He presented at Think this week and shared an insightful session about the transformative potential of generative AI and foundation models and the role of watsonx in enabling such advancements.AI With Tarun | AI Engineer. I help you build and learn AI for free 👨‍💻 🗣️ AI/ML Interview Series 📰 Cr... YouTube. Instagram. X. Here is the Prompt Guide. AI With Tarun. Instagram. Twitter. Join our Discord Community.I help you Build and learn AI for free 👨‍💻💸 My name is Tarun Jain. I'm a passionate coder with expertise in GenAI, Machine Learning, Image Processing, and Deep Learning. I currently work as a DevRel & Data Scientist at AI Planet, and a Google Developer Expert in AI/ML. I was also part of Google Summer of Code 23(GSoC23) at caMicroscope and an Ex-Research Intern at CCCIR.\n",
            "\u001b[0m> Running step 6f4257af-8627-4b09-9e4d-df42a648caba. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer.\n",
            "Answer: Tarun Jain is an AI engineer who offers free resources to help people learn and build AI. He has expertise in generative AI, machine learning, image processing, and deep learning. Tarun works as a Developer Relations & Data Scientist at AI Planet and is a Google Developer Expert in AI/ML. He has also participated in Google Summer of Code 2023 (GSoC23) at caMicroscope and was an Ex-Research Intern at CCCIR. Additionally, he is involved in creating and developing IBM's next-generation AI platform, watsonx.\n",
            "\n",
            "Analysis:\n",
            "- **Expertise**: Tarun has a strong background in AI and machine learning, with experience in both industry and research.\n",
            "- **Free Resources**: He provides free educational content, which can be very beneficial for those looking to learn AI without financial barriers.\n",
            "- **Industry Involvement**: His work with IBM and other organizations indicates that he is well-connected and up-to-date with the latest advancements in the field.\n",
            "- **Community Engagement**: Tarun is active on various platforms like YouTube, Instagram, and Twitter, and has a Discord community, suggesting a commitment to engaging with and helping others.\n",
            "\n",
            "Should people follow him?\n",
            "Yes, people interested in AI and machine learning should consider following Tarun Jain. His expertise, free educational resources, industry involvement, and community engagement make him a valuable resource for learning and staying updated in the field of AI.\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u46VVcnph2BV",
        "outputId": "c8908ff2-f2fc-4474-dc98-bd895c33d725"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tarun Jain is an AI engineer who offers free resources to help people learn and build AI. He has expertise in generative AI, machine learning, image processing, and deep learning. Tarun works as a Developer Relations & Data Scientist at AI Planet and is a Google Developer Expert in AI/ML. He has also participated in Google Summer of Code 2023 (GSoC23) at caMicroscope and was an Ex-Research Intern at CCCIR. Additionally, he is involved in creating and developing IBM's next-generation AI platform, watsonx.\n",
            "\n",
            "Analysis:\n",
            "- **Expertise**: Tarun has a strong background in AI and machine learning, with experience in both industry and research.\n",
            "- **Free Resources**: He provides free educational content, which can be very beneficial for those looking to learn AI without financial barriers.\n",
            "- **Industry Involvement**: His work with IBM and other organizations indicates that he is well-connected and up-to-date with the latest advancements in the field.\n",
            "- **Community Engagement**: Tarun is active on various platforms like YouTube, Instagram, and Twitter, and has a Discord community, suggesting a commitment to engaging with and helping others.\n",
            "\n",
            "Should people follow him?\n",
            "Yes, people interested in AI and machine learning should consider following Tarun Jain. His expertise, free educational resources, industry involvement, and community engagement make him a valuable resource for learning and staying updated in the field of AI.\n"
          ]
        }
      ]
    }
  ]
}